{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============\n",
    "# 《数据采集自检程序》1.9.5\n",
    "## 一.基础信息检查\n",
    "## 二.title、raw_title字段检查\n",
    "## 三. keywords、terms字段查询\n",
    "## 四. authors字段检查\n",
    "## 五. src、sid、lang、venue、ts字段检查\n",
    "## 六. issn、isbn、doi、pdf_src、paper_type、editor字段检查\n",
    "## 七. year、volume、issue、page_start、page_end、page_str字段查询\n",
    "# ============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 以下两种为读取json文件的函数，运行一种无法读取，请尝试切换另一种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('E:\\.metadata\\alrjournal_journals_urls_col.json',encoding='utf-8',lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_0 = json.load(open('E:\\\\.metadata\\\\alrjournal_journals_urls_col.json',encoding = 'utf-8'))\n",
    "\n",
    "data = pd.read_json((json.dumps(data_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_title</th>\n",
       "      <th>hash</th>\n",
       "      <th>pdf_src</th>\n",
       "      <th>lang</th>\n",
       "      <th>year</th>\n",
       "      <th>oa_type</th>\n",
       "      <th>...</th>\n",
       "      <th>abstract</th>\n",
       "      <th>reference</th>\n",
       "      <th>corresponding_raw</th>\n",
       "      <th>emails</th>\n",
       "      <th>authors</th>\n",
       "      <th>issue</th>\n",
       "      <th>page_end</th>\n",
       "      <th>page_str</th>\n",
       "      <th>citation</th>\n",
       "      <th>orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$oid': '5f21366ff53d79186c04cf49'}</td>\n",
       "      <td>{'$date': '2020-07-29T16:42:23.000+0000'}</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/full...</td>\n",
       "      <td>{'unknown': 'Satellite image analysis reveals ...</td>\n",
       "      <td>{'unknown': '&lt;h2 class=\"title\"&gt;Satellite image...</td>\n",
       "      <td>siarcisbavpbvdtl3y</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/pdf/...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020</td>\n",
       "      <td>free</td>\n",
       "      <td>...</td>\n",
       "      <td>{'en': '&lt;p&gt;Seagrass meadows are fragile ecosys...</td>\n",
       "      <td>[{'unknown': '&lt;li&gt;\n",
       "                &lt;a name=\"R1...</td>\n",
       "      <td>\\n* Corresponding author: nguyenxuanvi@gmail.c...</td>\n",
       "      <td>nguyenxuanvi@gmail.com</td>\n",
       "      <td>[{'pos': 0, 'name': {'unknown': 'Trong-Thach V...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'$oid': '5f213675f53d79186c04cf4a'}</td>\n",
       "      <td>{'$date': '2020-07-29T16:42:29.000+0000'}</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/abs/...</td>\n",
       "      <td>{'unknown': 'Pattern of movements within a hom...</td>\n",
       "      <td>{'unknown': '&lt;h2 class=\"title\"&gt;Pattern of move...</td>\n",
       "      <td>pomwahritci(sbteggel</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/pdf/...</td>\n",
       "      <td>en</td>\n",
       "      <td>2015</td>\n",
       "      <td>free</td>\n",
       "      <td>...</td>\n",
       "      <td>{'en': '&lt;p&gt;This study determined the movements...</td>\n",
       "      <td>[{'unknown': '&lt;meta name=\"citation_reference\" ...</td>\n",
       "      <td>a  Corresponding author: eric.clua@gmail.com</td>\n",
       "      <td>eric.clua@gmail.com</td>\n",
       "      <td>[{'pos': 0, 'name': {'unknown': 'Eric Clua'}, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>53-58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'$oid': '5f213676f53d79186c04cf4b'}</td>\n",
       "      <td>{'$date': '2020-07-29T16:42:30.000+0000'}</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/abs/...</td>\n",
       "      <td>{'unknown': 'Variation of antioxidant/detoxifi...</td>\n",
       "      <td>{'unknown': '&lt;h2 class=\"title\"&gt;Variation of an...</td>\n",
       "      <td>voaeairtbitgcpt</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/pdf/...</td>\n",
       "      <td>en</td>\n",
       "      <td>2015</td>\n",
       "      <td>free</td>\n",
       "      <td>...</td>\n",
       "      <td>{'en': '&lt;p&gt;Responses of four toxicological ind...</td>\n",
       "      <td>[{'unknown': '&lt;meta name=\"citation_reference\" ...</td>\n",
       "      <td>a  Corresponding author: jerrylee200224@126.com</td>\n",
       "      <td>jerrylee200224@126.com</td>\n",
       "      <td>[{'pos': 0, 'name': {'unknown': 'Lei Li'}, 'or...</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45-51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'$oid': '5f213677f53d79186c04cf4c'}</td>\n",
       "      <td>{'$date': '2020-07-29T16:42:21.000+0000'}</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/full...</td>\n",
       "      <td>{'unknown': 'First record of Pampus minor (Act...</td>\n",
       "      <td>{'unknown': '&lt;h2 class=\"title\"&gt;First record of...</td>\n",
       "      <td>fropm(psftcwowc</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/pdf/...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020</td>\n",
       "      <td>free</td>\n",
       "      <td>...</td>\n",
       "      <td>{'en': '&lt;p&gt;&lt;i&gt;Pampus&lt;/i&gt; fishes (Perciformes: ...</td>\n",
       "      <td>[{'unknown': '&lt;li&gt;\n",
       "                &lt;a name=\"R1...</td>\n",
       "      <td>\\n* Corresponding author: lshlin@tio.org.cn; l...</td>\n",
       "      <td>lshlin@tio.org.cn;liyuan@tio.org.cn</td>\n",
       "      <td>[{'pos': 0, 'name': {'unknown': 'Cheng Liu'}, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'$oid': '5f21367bf53d79186c04cf4d'}</td>\n",
       "      <td>{'$date': '2020-07-29T16:42:23.000+0000'}</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/abs/...</td>\n",
       "      <td>{'unknown': 'Sex-based spatial segregation of ...</td>\n",
       "      <td>{'unknown': '&lt;h2 class=\"title\"&gt;Sex-based spati...</td>\n",
       "      <td>sssoabsclitncgl</td>\n",
       "      <td>[https://www.alr-journal.org/articles/alr/pdf/...</td>\n",
       "      <td>en</td>\n",
       "      <td>2013</td>\n",
       "      <td>free</td>\n",
       "      <td>...</td>\n",
       "      <td>{'en': '&lt;p&gt;Conservation of threatened large sh...</td>\n",
       "      <td>[{'unknown': '&lt;meta name=\"citation_reference\" ...</td>\n",
       "      <td>a Corresponding author: jwerry@oc-research.com</td>\n",
       "      <td>jwerry@oc-research.com</td>\n",
       "      <td>[{'pos': 0, 'name': {'unknown': 'Jonathan Mark...</td>\n",
       "      <td>4</td>\n",
       "      <td>288.0</td>\n",
       "      <td>281-288</td>\n",
       "      <td>[{'unknown': '&lt;article data-dkey=\"10.1051/alr/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id  \\\n",
       "0  {'$oid': '5f21366ff53d79186c04cf49'}   \n",
       "1  {'$oid': '5f213675f53d79186c04cf4a'}   \n",
       "2  {'$oid': '5f213676f53d79186c04cf4b'}   \n",
       "3  {'$oid': '5f213677f53d79186c04cf4c'}   \n",
       "4  {'$oid': '5f21367bf53d79186c04cf4d'}   \n",
       "\n",
       "                                          ts  \\\n",
       "0  {'$date': '2020-07-29T16:42:23.000+0000'}   \n",
       "1  {'$date': '2020-07-29T16:42:29.000+0000'}   \n",
       "2  {'$date': '2020-07-29T16:42:30.000+0000'}   \n",
       "3  {'$date': '2020-07-29T16:42:21.000+0000'}   \n",
       "4  {'$date': '2020-07-29T16:42:23.000+0000'}   \n",
       "\n",
       "                                                 url  \\\n",
       "0  [https://www.alr-journal.org/articles/alr/full...   \n",
       "1  [https://www.alr-journal.org/articles/alr/abs/...   \n",
       "2  [https://www.alr-journal.org/articles/alr/abs/...   \n",
       "3  [https://www.alr-journal.org/articles/alr/full...   \n",
       "4  [https://www.alr-journal.org/articles/alr/abs/...   \n",
       "\n",
       "                                               title  \\\n",
       "0  {'unknown': 'Satellite image analysis reveals ...   \n",
       "1  {'unknown': 'Pattern of movements within a hom...   \n",
       "2  {'unknown': 'Variation of antioxidant/detoxifi...   \n",
       "3  {'unknown': 'First record of Pampus minor (Act...   \n",
       "4  {'unknown': 'Sex-based spatial segregation of ...   \n",
       "\n",
       "                                           raw_title                  hash  \\\n",
       "0  {'unknown': '<h2 class=\"title\">Satellite image...    siarcisbavpbvdtl3y   \n",
       "1  {'unknown': '<h2 class=\"title\">Pattern of move...  pomwahritci(sbteggel   \n",
       "2  {'unknown': '<h2 class=\"title\">Variation of an...       voaeairtbitgcpt   \n",
       "3  {'unknown': '<h2 class=\"title\">First record of...       fropm(psftcwowc   \n",
       "4  {'unknown': '<h2 class=\"title\">Sex-based spati...       sssoabsclitncgl   \n",
       "\n",
       "                                             pdf_src lang  year oa_type  ...  \\\n",
       "0  [https://www.alr-journal.org/articles/alr/pdf/...   en  2020    free  ...   \n",
       "1  [https://www.alr-journal.org/articles/alr/pdf/...   en  2015    free  ...   \n",
       "2  [https://www.alr-journal.org/articles/alr/pdf/...   en  2015    free  ...   \n",
       "3  [https://www.alr-journal.org/articles/alr/pdf/...   en  2020    free  ...   \n",
       "4  [https://www.alr-journal.org/articles/alr/pdf/...   en  2013    free  ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  {'en': '<p>Seagrass meadows are fragile ecosys...   \n",
       "1  {'en': '<p>This study determined the movements...   \n",
       "2  {'en': '<p>Responses of four toxicological ind...   \n",
       "3  {'en': '<p><i>Pampus</i> fishes (Perciformes: ...   \n",
       "4  {'en': '<p>Conservation of threatened large sh...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  [{'unknown': '<li>\n",
       "                <a name=\"R1...   \n",
       "1  [{'unknown': '<meta name=\"citation_reference\" ...   \n",
       "2  [{'unknown': '<meta name=\"citation_reference\" ...   \n",
       "3  [{'unknown': '<li>\n",
       "                <a name=\"R1...   \n",
       "4  [{'unknown': '<meta name=\"citation_reference\" ...   \n",
       "\n",
       "                                   corresponding_raw  \\\n",
       "0  \\n* Corresponding author: nguyenxuanvi@gmail.c...   \n",
       "1       a  Corresponding author: eric.clua@gmail.com   \n",
       "2    a  Corresponding author: jerrylee200224@126.com   \n",
       "3  \\n* Corresponding author: lshlin@tio.org.cn; l...   \n",
       "4     a Corresponding author: jwerry@oc-research.com   \n",
       "\n",
       "                                emails  \\\n",
       "0               nguyenxuanvi@gmail.com   \n",
       "1                  eric.clua@gmail.com   \n",
       "2               jerrylee200224@126.com   \n",
       "3  lshlin@tio.org.cn;liyuan@tio.org.cn   \n",
       "4               jwerry@oc-research.com   \n",
       "\n",
       "                                             authors issue page_end page_str  \\\n",
       "0  [{'pos': 0, 'name': {'unknown': 'Trong-Thach V...   NaN      NaN      NaN   \n",
       "1  [{'pos': 0, 'name': {'unknown': 'Eric Clua'}, ...     1     58.0    53-58   \n",
       "2  [{'pos': 0, 'name': {'unknown': 'Lei Li'}, 'or...     1     51.0    45-51   \n",
       "3  [{'pos': 0, 'name': {'unknown': 'Cheng Liu'}, ...   NaN      NaN      NaN   \n",
       "4  [{'pos': 0, 'name': {'unknown': 'Jonathan Mark...     4    288.0  281-288   \n",
       "\n",
       "                                            citation orgs  \n",
       "0                                                NaN  NaN  \n",
       "1                                                NaN  NaN  \n",
       "2                                                NaN  NaN  \n",
       "3                                                NaN  NaN  \n",
       "4  [{'unknown': '<article data-dkey=\"10.1051/alr/...  NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============\n",
    "# 一. 基础信息查询\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量： 1271\n"
     ]
    }
   ],
   "source": [
    "print('数据总量：',len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据包含字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('数据包含的字段名称如下')\n",
    "data_str_len = len(data.columns)\n",
    "for i in range(data_str_len):    \n",
    "    print(data.columns[i])\n",
    "print('数据字段数目：' + str(data_str_len) + '\\n')\n",
    "\n",
    "importion_str = ['url','title','raw_title','year','src','sid','ts']\n",
    "importion_str_tag = 0\n",
    "for i in range(len(importion_str)):\n",
    "    if importion_str[i] not in data.columns:\n",
    "        print('--------------------')\n",
    "        print('异常，可能缺少必填字段' + importion_str[i])\n",
    "    else:\n",
    "        importion_str_tag = 1\n",
    "if importion_str_tag == 0:\n",
    "    print('正常，不缺少任何必填字段！')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 检查是否存在重复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllist = []\n",
    "for url in data['url']:\n",
    "    urllist.append(url[0])\n",
    "\n",
    "url_list = list(set(urllist))\n",
    "\n",
    "if len(url_list) == len(urllist):\n",
    "    print('正常，未发现重复数据！')\n",
    "else:\n",
    "    print('异常，可能存在重复数据')\n",
    "    print('【重复数据量 / 数据总量】  <==>  【',len(urllist)-len(url_list),'/',len(data),'】\\n')\n",
    "\n",
    "    #展现重复元素和重复次数\n",
    "    repeation_tag = dict(Counter(urllist))\n",
    "    for key,value in repeation_tag.items():\n",
    "        if value>1:\n",
    "            print('url：',key,'\\t出现次数：',value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 检查url的数据类型（url-List[String]）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'url' in data.columns:\n",
    "    have_url = data[data['url'].notnull()]\n",
    "    url_type = []\n",
    "    url_type_warn = 0\n",
    "    for i in range(len(have_url)):\n",
    "        url_type.append(str(isinstance(have_url.iloc[i]['url'],list)))\n",
    "        if not isinstance(have_url.iloc[i]['url'],list):\n",
    "            url_type_warn = url_type_warn + 1\n",
    "    if 'False' not in url_type:\n",
    "        print('正常，url数据类型正确')\n",
    "    else:\n",
    "        print('异常，url数据类型可能存在错误')\n",
    "        print('【url数据类型可能存在错误的数据量 / 存在url的数据总量】  <==>  【',url_type_warn,'/',len(have_url),'】\\n')\n",
    "        for i in range(len(have_url)):\n",
    "            if not isinstance(have_url.iloc[i]['url'],list):\n",
    "                print('出现问题的url数据类型：',type(have_url.iloc[i]['url']))\n",
    "else:\n",
    "    print('异常，可能缺少必填字段url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============\n",
    "# 二. title, raw_title字段查询\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 检查title和raw_title的数据类型（title-MultiLangString、raw_title-MultiLangHtmlString）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 title的数据类型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'title' in data.columns:\n",
    "    have_title = data[data['title'].notnull()]\n",
    "    title_type = []\n",
    "    title_type_warn = 0\n",
    "    for i in range(len(have_title)):\n",
    "        title_type.append(str(isinstance(have_title.iloc[i]['title'],dict)))\n",
    "        if not isinstance(have_title.iloc[i]['title'],dict):\n",
    "            title_type_warn = title_type_warn + 1\n",
    "    if 'False' not in title_type:\n",
    "        print('正常，title数据类型正确')\n",
    "    else:\n",
    "        print('异常，title数据类型可能存在错误')\n",
    "        print('【title数据类型可能存在错误的数据量 / 存在title的数据总量】  <==>  【',title_type_warn,'/',len(have_title),'】\\n')\n",
    "        for i in range(len(have_title)):\n",
    "            if not isinstance(have_title.iloc[i]['title'],dict):\n",
    "                print('出现问题的title数据类型：',type(have_title.iloc[i]['title']))\n",
    "                print('url：',have_title.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少必填字段title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 raw_title的数据类型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'raw_title' in data.columns:\n",
    "    have_raw_title = data[data['raw_title'].notnull()]\n",
    "    raw_title_type = []\n",
    "    raw_title_type_warn = 0\n",
    "\n",
    "    for i in range(len(have_raw_title)):\n",
    "        raw_title_type.append(str(isinstance(have_raw_title.iloc[i]['raw_title'],dict)))\n",
    "        if not isinstance(have_raw_title.iloc[i]['raw_title'],dict):\n",
    "            raw_title_type_warn = raw_title_type_warn + 1\n",
    "        else:\n",
    "            lang_list = list(have_raw_title.iloc[i]['raw_title'].keys())\n",
    "            for t in range(len(lang_list)):\n",
    "                if (have_raw_title.iloc[i]['raw_title'][lang_list[t]][0] != '<') or (have_raw_title.iloc[i]['raw_title'][lang_list[t]][-1] != '>') :\n",
    "                    raw_title_type_warn = raw_title_type_warn + 1\n",
    "                    raw_title_type.append('False')\n",
    "    if 'False' not in raw_title_type:\n",
    "        print('正常，raw_title数据类型正确')\n",
    "    else:\n",
    "        print('异常，raw_title数据类型可能存在错误')\n",
    "        print('【raw_title数据类型可能存在错误的数据量 / 存在raw_title的数据总量】  <==>  【',raw_title_type_warn,'/',len(have_raw_title),'】\\n')\n",
    "        for i in range(len(have_raw_title)):\n",
    "            if not isinstance(have_raw_title.iloc[i]['raw_title'],dict):\n",
    "                print('出现问题的raw_title数据类型：',type(have_raw_title.iloc[i]['raw_title']))\n",
    "                print('url：',have_raw_title.iloc[i]['url'][0],'\\n')\n",
    "            else:\n",
    "                lang_list = list(have_raw_title.iloc[i]['raw_title'].keys())\n",
    "                for t in range(len(lang_list)):\n",
    "                    if (have_raw_title.iloc[i]['raw_title'][lang_list[t]][0] != '<') or (have_raw_title.iloc[i]['raw_title'][lang_list[t]][-1] != '>') :\n",
    "                        print('raw_title可能非Html String类型：')\n",
    "                        print(lang_list[t],': ',have_raw_title.iloc[i]['raw_title'][lang_list[t]])\n",
    "                        print('url：',have_raw_title.iloc[i]['url'][0],'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少必填字段raw_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 检查raw_title和title的数量、缺失情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 没有title字段，没有raw_title字段 情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('title' in data.columns) and ('raw_title' in data.columns):\n",
    "    no_title = data[data['title'].isnull()]\n",
    "    no_title_no_raw_title = no_title[no_title['raw_title'].isnull()]\n",
    "\n",
    "    if len(no_title_no_raw_title):\n",
    "        print('异常，可能存在没有title，没有raw_title的情况')\n",
    "        print('【没有title，没有raw_title的数据量 / 数据总量】  <==>  【',len(no_title_no_raw_title),'/',len(data),'】\\n')\n",
    "        print('请详细检查以下数据源：')\n",
    "        for i in range(len(no_title_no_raw_title)):\n",
    "            print('url：',no_title_no_raw_title.iloc[i]['url'][0])\n",
    "    else:\n",
    "        print('正常，不存在没有title，没有raw_title的情况')\n",
    "else:\n",
    "    if 'title' not in data.columns:\n",
    "        print('异常，可能缺少必填字段title')\n",
    "    if 'raw_title' not in data.columns:\n",
    "        print('异常，可能缺少必填字段raw_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 有title字段，没有raw_title字段 情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('title' in data.columns) and ('raw_title' in data.columns):\n",
    "    have_title = data[data['title'].notnull()]\n",
    "    have_title_no_raw_title = have_title[have_title['raw_title'].isnull()]\n",
    "\n",
    "    if len(have_title_no_raw_title):\n",
    "        print('异常，可能存在有title，没有raw_title的情况\\n')\n",
    "        print('【有title，没有raw_title的数据量 / 数据总量】  <==>  【',len(have_title_no_raw_title),'/',len(data),'】\\n')\n",
    "        print('请详细检查以下数据源：')\n",
    "        for i in range(len(have_title_no_raw_title)):\n",
    "            print('url：',have_title_no_raw_title.iloc[i]['url'][0])\n",
    "    else:\n",
    "        print('正常，不存在有title，没有raw_title的情况')\n",
    "else:\n",
    "    if 'title' not in data.columns:\n",
    "        print('异常，可能缺少必填字段title')\n",
    "    if 'raw_title' not in data.columns:\n",
    "        print('异常，可能缺少必填字段raw_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 检查 没有title字段，有raw_title字段 情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('title' in data.columns) and ('raw_title' in data.columns):\n",
    "    have_raw_title = data[data['raw_title'].notnull()]\n",
    "    have_raw_title_no_title = have_raw_title[have_raw_title['title'].isnull()]\n",
    "\n",
    "    if len(have_raw_title_no_title):\n",
    "        print('异常，可能存在没有title，有raw_title的情况\\n')\n",
    "        print('【没有title，有raw_title的数据量 / 数据总量】  <==>  【',len(have_raw_title_no_title),'/',len(data),'】\\n')\n",
    "        print('请详细检查以下数据源：')\n",
    "        for i in range(len(have_raw_title_no_title)):\n",
    "            print('url：',have_raw_title_no_title.iloc[i]['url'][0])\n",
    "    else:\n",
    "        print('正常，不存在没有title，有raw_title的情况')\n",
    "else:\n",
    "    if 'title' not in data.columns:\n",
    "        print('异常，可能缺少必填字段title')\n",
    "    if 'raw_title' not in data.columns:\n",
    "        print('异常，可能缺少必填字段raw_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 检查title和raw_title常见问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 title字段为空情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'title' in data.columns:\n",
    "    have_title = data[data['title'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_title)):\n",
    "        lang_list = list(have_title.iloc[i]['raw_title'].keys())\n",
    "        for t in range(len(lang_list)):\n",
    "            title = have_title.iloc[i]['title'][lang_list[t]].strip()\n",
    "            if title == '':\n",
    "                if tag == 0:\n",
    "                    tag = 1\n",
    "                    print('异常，可能存在title字段为空的情况\\n')\n",
    "                    print('请详细检查以下数据源：')\n",
    "                print('title: ',have_title.iloc[i]['title'])\n",
    "                print('url：',have_title.iloc[i]['url'][0])\n",
    "    if tag == 0:\n",
    "        print('正常，未发现title字段为空的情况')\n",
    "else:\n",
    "    print('异常，可能缺少必填字段title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 raw_title字段为空情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'raw_title' in data.columns:\n",
    "    have_raw_title = data[data['raw_title'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_raw_title)):\n",
    "        lang_list = list(have_raw_title.iloc[i]['raw_title'].keys())\n",
    "        for t in range(len(lang_list)):\n",
    "            raw_title = have_raw_title.iloc[i]['raw_title'][lang_list[t]].strip()\n",
    "            if raw_title == '':\n",
    "                if tag == 0:\n",
    "                    tag = 1\n",
    "                    print('异常，可能存在raw_title字段为空的情况\\n')\n",
    "                    print('请详细检查以下数据源：')\n",
    "                print('raw_title: ',have_raw_title.iloc[i]['title'])\n",
    "                print('url：', have_raw_title.iloc[i]['url'][0])\n",
    "    if tag == 0:\n",
    "        print('正常，未发现raw_title字段为空的情况')\n",
    "else:\n",
    "    print('异常，可能缺少必填字段raw_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 检查title字段内容是否存在常见问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'title' in data.columns:\n",
    "    have_title = data[data['title'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_title)):\n",
    "        lang_list = list(have_title.iloc[i]['raw_title'].keys())\n",
    "        for t in range(len(lang_list)):\n",
    "            title = have_title.iloc[i]['title'][lang_list[t]]\n",
    "            if title:\n",
    "                if ('\\n' in title) or ('\\t' in title) or ('\\r' in title) or ('  ' in title) or (not title[0].isalnum()) or (title[-1]==' '):\n",
    "                    tag = tag + 1\n",
    "                    if tag == 1:\n",
    "                        print('异常，title字段中可能存在问题')\n",
    "                    if ('\\n' in title) or ('\\t' in title) or ('\\r' in title):\n",
    "                        print('title：',have_title.iloc[i]['title'])\n",
    "                        print('title可能存在转义字符')\n",
    "                        print('url：',have_title.iloc[i]['url'][0],'\\n')\n",
    "                    if ('  ' in title) or (title[0] == ' ') or (title[-1] == ' '):\n",
    "                        print('title：',have_title.iloc[i]['title'])\n",
    "                        print('title可能存在多余空格')\n",
    "                        print('url：',have_title.iloc[i]['url'][0],'\\n')\n",
    "                    if not title[0].isalnum():\n",
    "                        if title[0] != ' ':\n",
    "                            print('title：',have_title.iloc[i]['title'])\n",
    "                            print('title中存在异常')\n",
    "                            print('url：',have_title.iloc[i]['url'][0],'\\n')\n",
    "            else:\n",
    "                tag = 1\n",
    "                print('title：',have_title.iloc[i]['title'])\n",
    "                print('title存在内容为空')\n",
    "                print('url：',have_title.iloc[i]['url'][0],'\\n')\n",
    "    if tag == 0:\n",
    "        print('正常，title字段未发现常见问题')\n",
    "else:\n",
    "    print('异常，可能缺少必填字段title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============\n",
    "# 二. abstract字段查询\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 检查abstract数据类型（abstract-MultiLangHtmlString）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'abstract' in data.columns:\n",
    "    have_abstract = data[data['abstract'].notnull()]\n",
    "    abstract_type = []\n",
    "    abstract_type_warn = 0\n",
    "    if 'abstract' in data.columns:\n",
    "        for i in range(len(have_abstract)):\n",
    "            abstract_type.append(str(isinstance(have_abstract.iloc[i]['abstract'],dict)))\n",
    "            if not isinstance(have_abstract.iloc[i]['abstract'],dict):\n",
    "                abstract_type_warn = abstract_type_warn + 1\n",
    "        if 'False' not in abstract_type:\n",
    "            print('正常，abstract数据类型正确')\n",
    "        else:\n",
    "            print('异常，abstract数据类型可能存在错误')\n",
    "            print('【abstract数据类型可能存在错误的数据量 / 存在abstract的数据总量】  <==>  【',abstract_type_warn,'/',len(have_abstract),'】\\n')\n",
    "            for i in range(len(have_abstract)):\n",
    "                if not isinstance(have_abstract.iloc[i]['abstract'],dict):\n",
    "                    print('出现问题的abstract数据类型：',type(have_abstract.iloc[i]['abstract']))\n",
    "                    print('url：',have_abstract.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少必填字段abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 检查abstract数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 abstract字段缺失的情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'abstract' in data.columns:\n",
    "    no_abstract = data[data['abstract'].isnull()]\n",
    "    if len(no_abstract) == 0:\n",
    "        print('正常，未发现abstract缺失现象')\n",
    "    else:\n",
    "        print('异常，可能存在abstract缺失现象')\n",
    "        print('【abstract数据类型可能缺失的数据量 / 数据总量】  <==>  【',len(no_abstract),'/',len(data),'】')\n",
    "        print('请从以下随机抽样检查，查看是否存在抓取遗漏：\\n')\n",
    "        for i in range(len(no_abstract)):\n",
    "            print('url：',no_abstract.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少必填字段abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 abstract字段异常的情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'abstract' in data.columns:\n",
    "    have_abstract = data[data['abstract'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_abstract)):\n",
    "        lang_list = list(have_abstract.iloc[i]['abstract'].keys())\n",
    "        for t in range(len(lang_list)):\n",
    "            abstract = have_abstract.iloc[i]['abstract'][lang_list[t]].strip()\n",
    "            if len(abstract) != 0:\n",
    "                if len(abstract) < 200 :\n",
    "                    if tag == 0:\n",
    "                        tag = 1\n",
    "                        print('异常，abstract过短，可能存在问题')\n",
    "                    print('abstract : ',have_abstract.iloc[i]['abstract'])\n",
    "                    print('url：',have_abstract.iloc[i]['url'][0],'\\n')\n",
    "            else:\n",
    "                print('异常，abstract字段可能为空')\n",
    "                print('abstract : ',have_abstract.iloc[i]['abstract'])\n",
    "                print('url：',have_abstract.iloc[i]['url'][0],'\\n')\n",
    "    if tag == 0:\n",
    "        print('正常，未发现abstract异常情况')\n",
    "                \n",
    "else:\n",
    "    print('异常，可能缺少必填字段abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============\n",
    "# 三. keywords、terms字段检查\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 检查keywords字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 检查 keywords字段数据格式（keywords-MultiLangString）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'keywords' in data.columns:\n",
    "    have_keywords = data[data['keywords'].notnull()]\n",
    "    keywords_type = []\n",
    "    keywords_type_warn = 0\n",
    "    for i in range(len(have_keywords)):\n",
    "        keywords_type.append(str(isinstance(have_keywords.iloc[i]['keywords'],dict)))\n",
    "        if not isinstance(have_keywords.iloc[i]['keywords'],dict):\n",
    "            keywords_type_warn = keywords_type_warn + 1\n",
    "    if 'False' not in keywords_type:\n",
    "        print('正常，keywords数据类型正确')\n",
    "    else:\n",
    "        print('异常，keywords数据类型可能存在错误')\n",
    "        print('【keywords数据类型可能存在错误的数据量 / 存在keywords的数据总量】  <==>  【',keywords_type_warn,'/',len(have_keywords),'】\\n')\n",
    "        for i in range(len(have_keywords)):\n",
    "            if not isinstance(have_keywords.iloc[i]['keywords'],dict):\n",
    "                print('出现问题的keywords数据类型：',type(have_keywords.iloc[i]['keywords']))\n",
    "                print('url：',have_keywords.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少字段keywords，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 keywords字段缺失问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'keywords' in data.columns:\n",
    "    no_keywords = data[data['keywords'].isnull()]\n",
    "    if len(no_keywords) == 0:\n",
    "        print('正常，未发现keywords缺失现象')\n",
    "    else:\n",
    "        print('异常，可能存在keywords缺失现象')\n",
    "        print('【keywords数据类型可能缺失的数据量 / 数据总量】  <==>  【',len(no_keywords),'/',len(data),'】')\n",
    "        print('请从以下随机抽样检查，查看是否存在抓取遗漏：\\n')\n",
    "        for i in range(len(no_keywords)):\n",
    "            print('url：',no_keywords.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少字段keywords，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 检查 keywords字段数据问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "异常，keywords字段可能出现问题\n",
      "请详细检查以下keywords是否出现问题：\n",
      "\n",
      "keywords： {'en': 'Aquaculture economic assessment;endemic snail;aquatic resource conservation;financial assessment;human pressure on snail population;Monte Carlo;stochastic modelling;Pomacea patula catemacensis (P. p. catemacensis)'}\n",
      "url： https://www.alr-journal.org/articles/alr/full_html/2020/01/alr180056/alr180056.html \n",
      "\n",
      "keywords： {'en': 'Anadromous species;stock assessment;split-beam sonar;Oncorhynchus nerka;Oncorhynchus gorbuscha;Canada (British Columbia)'}\n",
      "url： https://www.alr-journal.org/articles/alr/abs/1998/02/alr8277/alr8277.html \n",
      "\n",
      "keywords： {'en': 'length-frequency data;seasonal growth;reproductive strategy;upwelling ecosystem;Clupeidae;Engraulidae;Talcahuano (Chile)'}\n",
      "url： https://www.alr-journal.org/articles/alr/abs/2001/02/alr1141/alr1141.html \n",
      "\n",
      "keywords： {'en': 'Combined quota and effort control;Bio-economic modelling;FLR (Fisheries Laboratory in language R)'}\n",
      "url： https://www.alr-journal.org/articles/alr/abs/2008/03/alr028-08/alr028-08.html \n",
      "\n",
      "keywords： {'en': 'Ecospace;Gulf of Gabes;fisheries management;marine protected areas (MPA)'}\n",
      "url： https://www.alr-journal.org/articles/alr/abs/2016/02/alr150064/alr150064.html \n",
      "\n",
      "keywords： {'en': 'Fishing impact;Food web;Ecopath;EwE;EcoTroph;Transfer efficiency;Bay of Biscay;Celtic Sea;Ecosystem approach to fisheries management (EAFM)'}\n",
      "url： https://www.alr-journal.org/articles/alr/full_html/2017/01/alr160078/alr160078.html \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'keywords' in data.columns:\n",
    "    have_keywords = data[data['keywords'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_keywords)):\n",
    "        lang_list = list(have_keywords.iloc[i]['keywords'].keys())\n",
    "        for t in range(len(lang_list)):\n",
    "            keywords = str(have_keywords.iloc[i]['keywords'][lang_list[t]]).split(';')\n",
    "            if len(keywords) == 1:\n",
    "                if keywords[0] == 'nan':\n",
    "                    continue\n",
    "                else:\n",
    "                    if tag == 0:\n",
    "                        tag = 1\n",
    "                        print('异常，keywords字段可能出现问题')\n",
    "                        print('请详细检查以下keywords是否出现问题：\\n')\n",
    "                    print('keywords：',have_keywords.iloc[i]['keywords'])\n",
    "                    print('url：',have_keywords.iloc[i]['url'][0],'\\n')\n",
    "            if (not have_keywords.iloc[i]['keywords'][lang_list[t]][0].isalnum()) or (not have_keywords.iloc[i]['keywords'][lang_list[t]][-1].isalnum()) or ('; ' in have_keywords.iloc[i]['keywords'][lang_list[t]]) or ('  ' in have_keywords.iloc[i]['keywords'][lang_list[t]]):\n",
    "                if tag == 0:\n",
    "                    tag = 1\n",
    "                    print('异常，keywords字段可能出现问题')\n",
    "                    print('请详细检查以下keywords是否出现问题：\\n')\n",
    "                print('keywords：',have_keywords.iloc[i]['keywords'])\n",
    "                print('url：',have_keywords.iloc[i]['url'][0],'\\n')\n",
    "    if tag == 0:\n",
    "        print('正常，未发现keywords存在问题')\n",
    "else:\n",
    "    print('异常，可能缺少字段keywords，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 检查terms字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 检查 terms字段数据格式（terms-MultiLangString）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'terms' in data.columns:\n",
    "    have_terms = data[data['terms'].notnull()]\n",
    "    terms_type = []\n",
    "    terms_type_warn = 0\n",
    "    for i in range(len(have_terms)):\n",
    "        terms_type.append(str(isinstance(have_terms.iloc[i]['terms'],dict)))\n",
    "        if not isinstance(have_terms.iloc[i]['terms'],dict):\n",
    "            terms_type_warn = terms_type_warn + 1\n",
    "    if 'False' not in terms_type:\n",
    "        print('正常，terms数据类型正确')\n",
    "    else:\n",
    "        print('异常，terms数据类型可能存在错误')\n",
    "        print('【terms数据类型可能存在错误的数据量 / 存在terms的数据总量】  <==>  【',terms_type_warn,'/',len(have_terms),'】\\n')\n",
    "        for i in range(len(have_terms)):\n",
    "            if not isinstance(have_terms.iloc[i]['terms'],dict):\n",
    "                print('出现问题的terms数据类型：',type(have_terms.iloc[i]['terms']))\n",
    "                print('url：',have_terms.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少字段terms，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 terms字段缺失问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'terms' in data.columns:\n",
    "    no_terms = data[data['terms'].isnull()]\n",
    "    if len(no_terms) == 0:\n",
    "        print('正常，未发现terms缺失现象')\n",
    "    else:\n",
    "        print('异常，可能存在terms缺失现象')\n",
    "        print('【terms数据类型可能缺失的数据量 / 数据总量】  <==>  【',len(no_terms),'/',len(data),'】')\n",
    "        print('请从以下随机抽样检查，查看是否存在抓取遗漏：\\n')\n",
    "        for i in range(len(no_terms)):\n",
    "            print('url：',no_terms.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少字段terms，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 检查 terms字段数据问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'terms' in data.columns:\n",
    "    have_terms = data[data['terms'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_terms)):\n",
    "        lang_list = list(have_terms.iloc[i]['terms'].keys())\n",
    "        for t in range(len(lang_list)):\n",
    "            terms = str(have_terms.iloc[i]['terms'][lang_list[t]]).split(';')\n",
    "            if len(terms) == 1:\n",
    "                if terms[0] == 'nan':\n",
    "                    continue\n",
    "                else:\n",
    "                    if tag == 0:\n",
    "                        tag = 1\n",
    "                        print('异常，terms字段可能出现问题')\n",
    "                        print('请详细检查以下terms是否出现问题：\\n')\n",
    "                    print('terms：',have_terms.iloc[i]['terms'])\n",
    "                    print('url：',have_terms.iloc[i]['url'][0],'\\n')\n",
    "            if (not have_terms.iloc[i]['terms'][lang_list[t]][0].isalnum()) or (not have_terms.iloc[i]['terms'][lang_list[t]][-1].isalnum()) or ('; ' in have_terms.iloc[i]['terms'][lang_list[t]]) or ('  ' in have_terms.iloc[i]['terms'][lang_list[t]]):\n",
    "                if tag == 0:\n",
    "                    tag = 1\n",
    "                    print('异常，terms字段可能出现问题')\n",
    "                    print('请详细检查以下terms是否出现问题：\\n')\n",
    "                print('terms：',have_terms.iloc[i]['terms'])\n",
    "                print('url：',have_terms.iloc[i]['url'][0],'\\n')\n",
    "    if tag == 0:\n",
    "        print('正常，未发现terms存在问题')\n",
    "else:\n",
    "    print('异常，可能缺少字段terms，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============\n",
    "# 四. authors字段检查\n",
    "### 1. 检查authors字段缺失情况\n",
    "### 2. 检查name字段\n",
    "### 3. 检查org字段\n",
    "### 4. 检查email字段\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 检查authors字段缺失情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    no_authors = data[data['authors'].isnull()]\n",
    "    if len(no_authors) == 0:\n",
    "        print('正常，未发现authors字段缺失情况')\n",
    "    else:\n",
    "        print('异常，可能存在authors缺失现象')\n",
    "        print('【authors数据类型可能缺失的数据量 / 数据总量】  <==>  【',len(no_authors),'/',len(data),'】')\n",
    "        print('请从以下随机抽样检查，查看是否存在抓取遗漏：\\n')\n",
    "        for i in range(len(no_authors)):\n",
    "            print('url：',no_authors.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 检查pos字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 pos字段数据是否缺失**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                author = have_authors.iloc[i]['authors'][n]\n",
    "                if 'pos' in author:\n",
    "                    tag = 0\n",
    "                else:\n",
    "                    tag = 1\n",
    "                    break\n",
    "    if tag == 0:\n",
    "        print('正常，未发现authors字段中pos缺失现象')\n",
    "    else:\n",
    "        print('异常，authors字段中可能缺少必填字段pos')\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 pos字段数据类型（pos-Int32）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                author = have_authors.iloc[i]['authors'][n]\n",
    "                if 'pos' in author:\n",
    "                    pos = author['pos']\n",
    "                    if not isinstance(pos,int):\n",
    "                        tag = 1\n",
    "                        break\n",
    "    if tag == 0:\n",
    "        print('正常，未发现authors字段中pos数据格式问题')\n",
    "    else:\n",
    "        print('异常，authors字段中pos字段格式可能出现错误')\n",
    "        print('要求格式为Int32，实际格式为',type(pos))\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 检查 pos字段数据问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                author = have_authors.iloc[i]['authors'][n]\n",
    "                if 'pos' in author:\n",
    "                    pos = author['pos']\n",
    "                    if isinstance(pos,int):\n",
    "                        if pos != n:\n",
    "                            tag = 1\n",
    "                            break\n",
    "    if tag == 0:\n",
    "        print('正常，未发现authors字段中pos数据问题')\n",
    "    else:\n",
    "        print('异常，authors字段中pos字段数据可能出现错误')\n",
    "        print('pos字段应该从 0 开始')\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 检查name字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 name字段数据问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                authors = have_authors.iloc[i]['authors'][n]\n",
    "                if 'name' in authors:\n",
    "                    namestr = authors['name']\n",
    "                    lang_list = list(namestr.keys())\n",
    "                    for t in range(len(lang_list)):\n",
    "                        if namestr[lang_list[t]] :\n",
    "                            if ('\\n' in namestr[lang_list[t]]) or ('\\t' in namestr[lang_list[t]]) or ('\\r' in namestr[lang_list[t]]):\n",
    "                                tag = 1\n",
    "                            if (len(namestr[lang_list[t]]) <= 1) or (len(namestr[lang_list[t]]) > 30) or (' and ' in namestr[lang_list[t]]):\n",
    "                                tag = 1\n",
    "                            if ('(' in namestr[lang_list[t]]) or (not namestr[lang_list[t]][0].isalpha()) or (not namestr[lang_list[t]][-1].isalpha()):\n",
    "                                if (namestr[lang_list[t]][0] == ' ') or (namestr[lang_list[t]][-1] == ' '):\n",
    "                                    tag = 1\n",
    "                                elif namestr[lang_list[t]][-1] != '.':\n",
    "                                    tag = 1\n",
    "                        else:\n",
    "                            tag = 1\n",
    "    if tag == 0:\n",
    "        print('正常，未发现name存在问题')\n",
    "    else:\n",
    "        print('异常，name字段可能出现问题')\n",
    "        print('请详细检查以下name是否出现问题：\\n')\n",
    "    \n",
    "        for i in range(len(have_authors)):\n",
    "            if len(have_authors.iloc[i]['authors']) != 0:\n",
    "                for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                    authors = have_authors.iloc[i]['authors'][n]\n",
    "                    if 'name' in authors:\n",
    "                        namestr = authors['name']\n",
    "                        lang_list = list(namestr.keys())\n",
    "                        for t in range(len(lang_list)):\n",
    "                            if namestr[lang_list[t]] :\n",
    "                                if ('\\n' in namestr[lang_list[t]]) or ('\\t' in namestr[lang_list[t]]) or ('\\r' in namestr[lang_list[t]]):\n",
    "                                    print('name中可能存在转义字符 ntr')\n",
    "                                    for t in range(len(lang_list)):\n",
    "                                        print(lang_list[t],' : ',namestr[lang_list[t]])\n",
    "                                    print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                                if (len(namestr[lang_list[t]]) <= 1) or (len(namestr[lang_list[t]]) > 30) or (' and ' in namestr[lang_list[t]]):\n",
    "                                    print('name太短或太长，可能有问题')\n",
    "                                    for t in range(len(lang_list)):\n",
    "                                        print(lang_list[t],' : ',namestr[lang_list[t]])\n",
    "                                    print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                                if ('(' in namestr[lang_list[t]]) or (not namestr[lang_list[t]][0].isalpha()) or (not namestr[lang_list[t]][-1].isalpha()):\n",
    "                                    if namestr[lang_list[t]].strip() == '':\n",
    "                                        print('name可能为空')\n",
    "                                        for t in range(len(lang_list)):\n",
    "                                            print(lang_list[t],' : ',namestr[lang_list[t]])\n",
    "                                        print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                                    elif (namestr[lang_list[t]][0] == ' ') or (namestr[lang_list[t]][-1] == ' '):\n",
    "                                        print('name两侧可能存在空格')\n",
    "                                        for t in range(len(lang_list)):\n",
    "                                            print(lang_list[t],' : ',namestr[lang_list[t]])\n",
    "                                        print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                                    elif namestr[lang_list[t]][-1] != '.':\n",
    "                                        print('name中可能存在异常')\n",
    "                                        for t in range(len(lang_list)):\n",
    "                                            print(lang_list[t],' : ',namestr[lang_list[t]])\n",
    "                                        print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                            else:\n",
    "                                    print('name为空')\n",
    "                                    for t in range(len(lang_list)):\n",
    "                                        print(lang_list[t],' : ',namestr[lang_list[t]])\n",
    "                                    print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 检查作者机构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查作者机构缺失问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            orgs=have_authors.iloc[i].get('orgs')\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                authors = have_authors.iloc[i]['authors'][n]\n",
    "                if 'org' not in authors and orgs==None:\n",
    "                    tag = 1\n",
    "    if tag == 0:\n",
    "        print('正常，未发现作者机构缺失问题')\n",
    "    else:\n",
    "        print('异常，可能缺失作者机构')\n",
    "        for i in range(len(have_authors)):\n",
    "            if len(have_authors.iloc[i]['authors']) != 0:\n",
    "                orgs=have_authors.iloc[i].get('orgs')\n",
    "                for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                    authors = have_authors.iloc[i]['authors'][n]\n",
    "                    if 'org' not in authors and orgs==None:\n",
    "                        print('name：',authors['name'])\n",
    "                        print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 org字段数据问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正常，未发现org存在问题\n"
     ]
    }
   ],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                authors = have_authors.iloc[i]['authors'][n]\n",
    "                if 'org' in authors:\n",
    "                    orglist = authors['org']\n",
    "                    if len(orglist) != 0:\n",
    "                        for t in range(len(orglist)):\n",
    "                            orgdic = orglist[t]\n",
    "                            lang_list = list(orgdic.keys())\n",
    "                            for q in range(len(lang_list)):\n",
    "                                lang = lang_list[q]\n",
    "                                if len(orglist[t]) != 0:\n",
    "                                    if ('\\n' in orglist[t][lang]) or ('\\t' in orglist[t][lang]) or ('\\r' in orglist[t][lang]) or ('  ' in orglist[t][lang]):\n",
    "                                        tag = 1\n",
    "                                    try:\n",
    "                                        if (not orglist[t][lang][0].isalnum()) or (not orglist[t][lang][-1].isalnum()):\n",
    "                                            if orglist[t][lang][-1] != '.' and orglist[t][lang][-1] != ')':\n",
    "                                                tag = 1\n",
    "                                    except Exception:\n",
    "                                        print(have_authors.iloc[i]['url'][0])\n",
    "                                    if '@' in orglist[t][lang]:\n",
    "                                        tag = 1\n",
    "                                else:\n",
    "                                    tag = 1\n",
    "                    else:\n",
    "                        tag = 1\n",
    "\n",
    "    if tag == 0:\n",
    "        print('正常，未发现org存在问题')\n",
    "    else:\n",
    "        print('异常，org字段可能出现问题')\n",
    "        print('请详细检查以下org是否出现问题：\\n')\n",
    "    \n",
    "        for i in range(len(have_authors)):\n",
    "            if len(have_authors.iloc[i]['authors']) != 0:\n",
    "                for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                    authors = have_authors.iloc[i]['authors'][n]\n",
    "                    if 'org' in authors:\n",
    "                        orglist = authors['org']\n",
    "                        if len(orglist) != 0:\n",
    "                            for t in range(len(orglist)):\n",
    "                                orgdic = orglist[t]\n",
    "                                lang_list = list(orgdic.keys())\n",
    "                                for q in range(len(lang_list)):\n",
    "                                    lang = lang_list[q]\n",
    "                                    if len(orglist[t]) != 0:\n",
    "                                        if ('\\n' in orglist[t][lang]) or ('\\t' in orglist[t][lang]) or ('\\r' in orglist[t][lang]):\n",
    "                                            print('org中可能存在转义字符')\n",
    "                                            print('org：',orglist[t])\n",
    "                                            print('url：',have_auAthors.iloc[i]['url'][0],'\\n')\n",
    "                                        if (not orglist[t][lang][0].isalnum()) or (not orglist[t][lang][-1].isalnum()):\n",
    "                                            if orglist[t][lang][-1] != '.' and orglist[t][lang][-1] != ')':\n",
    "                                                print('org中可能存在异常')\n",
    "                                                print('org：',orglist[t])\n",
    "                                                print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                                        if '@' in orglist[t][lang]:\n",
    "                                            print('org中可能存在异常')\n",
    "                                            print('org：',orglist[t])\n",
    "                                            print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                                        if '  ' in orglist[t][lang]:\n",
    "                                            print('org中可能存在多余空格')\n",
    "                                            print('org：',orglist[t])\n",
    "                                            print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                                    else:\n",
    "                                        print('org中可能为空')\n",
    "                                        print('org：',orglist)\n",
    "                                        print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                        else:\n",
    "                            print('org中可能为空')\n",
    "                            print('org：',orglist)\n",
    "                            print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 检查email字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 email字段数据问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                authors = have_authors.iloc[i]['authors'][n]\n",
    "                if 'email' in authors:\n",
    "                    emailstr = authors['email']\n",
    "                    if emailstr :\n",
    "                        if ('\\n' in emailstr) or ('\\t' in emailstr) or ('\\r' in emailstr):\n",
    "                            tag = 1\n",
    "                        if (' ' in emailstr) or ('@' not in emailstr):\n",
    "                            tag = 1\n",
    "                        if ('(' in emailstr) or (not emailstr[0].isalpha()) or (not emailstr[-1].isalpha()):\n",
    "                            if (emailstr[0] == ' ') or (emailstr[-1] == ' '):\n",
    "                                tag = 1\n",
    "                    else:\n",
    "                        tag = 1\n",
    "    if tag == 0:\n",
    "        print('正常，未发现email存在问题')\n",
    "    else:\n",
    "        print('异常，email字段可能出现问题')\n",
    "        print('请详细检查以下email是否出现问题：\\n')\n",
    "    \n",
    "        for i in range(len(have_authors)):\n",
    "            if len(have_authors.iloc[i]['authors']) != 0:\n",
    "                for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                    authors = have_authors.iloc[i]['authors'][n]\n",
    "                    if 'email' in authors:\n",
    "                        emailstr = authors['email']\n",
    "                        if emailstr :\n",
    "                            if ('\\n' in emailstr) or ('\\t' in emailstr) or ('\\r' in emailstr):\n",
    "                                print('email中可能存在转义字符 ntr')\n",
    "                                print('email：',emailstr)\n",
    "                                print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                            if (' ' in emailstr) or ('@' not in emailstr):\n",
    "                                print('email中可能存在异常')\n",
    "                                print('email：',emailstr)\n",
    "                                print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                            if ('(' in emailstr) or (not emailstr[0].isalnum()) or (not emailstr[-1].isalpha()):\n",
    "                                if emailstr.strip() == '':\n",
    "                                    print('email可能为空')\n",
    "                                    print('email：',emailstr)\n",
    "                                    print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                                elif (emailstr[0] == ' ') or (emailstr[-1] == ' '):\n",
    "                                    print('email两侧可能存在空格')\n",
    "                                    print('email：',emailstr)\n",
    "                                    print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "                        else:\n",
    "                                print('email为空')\n",
    "                                print('email：',emailstr)\n",
    "                                print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.检查homepage字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)检查homepage数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                author = have_authors.iloc[i]['authors'][n]\n",
    "                if 'homepage' in author:\n",
    "                    homepage = author['homepage']\n",
    "                    if not isinstance(homepage,str):\n",
    "                        tag = 1\n",
    "                        print(\"homepage类型:\",type(homepage),have_authors.iloc[i]['url'][0])\n",
    "    if tag == 0:\n",
    "        print('正常，未发现authors字段中homepage类型有问题')\n",
    "    else:\n",
    "        print('异常，authors字段中homepage字段数据类型出现错误,应为String类型')\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)检查homepage数据缺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'authors' in data.columns:\n",
    "    have_authors = data[data['authors'].notnull()]\n",
    "    tag = 0\n",
    "    for i in range(len(have_authors)):\n",
    "        if len(have_authors.iloc[i]['authors']) != 0:\n",
    "            for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                authors = have_authors.iloc[i]['authors'][n]\n",
    "                if 'homepage' not in authors:\n",
    "                    tag = 1\n",
    "    if tag == 0:\n",
    "        print('正常，未发现homepage缺失问题')\n",
    "    else:\n",
    "        print('异常，可能缺失homepage')\n",
    "        for i in range(len(have_authors)):\n",
    "            if len(have_authors.iloc[i]['authors']) != 0:\n",
    "                for n in range(len(have_authors.iloc[i]['authors'])):\n",
    "                    authors = have_authors.iloc[i]['authors'][n]\n",
    "                    if 'homepage' not in authors:\n",
    "                        print('name：',authors['name'])\n",
    "                        print('url：',have_authors.iloc[i]['url'][0],'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少字段authors，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============\n",
    "# 五. reference、citation字段查询\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 检查reference字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 检查 reference字段数据格式（reference-List[MultiLangHtmlString]）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'reference' in data.columns:\n",
    "    have_reference = data[data['reference'].notnull()]\n",
    "    reference_type = []\n",
    "    reference_type_warn = 0\n",
    "\n",
    "    for i in range(len(have_reference)):\n",
    "        reference_type.append(str(isinstance(have_reference.iloc[i]['reference'],list)))\n",
    "        if not isinstance(have_reference.iloc[i]['reference'],list):\n",
    "            reference_type_warn = reference_type_warn + 1\n",
    "        else:\n",
    "            paper_reference = have_reference.iloc[i]['reference']\n",
    "            for n in range(len(paper_reference)):\n",
    "                reference = paper_reference[n]\n",
    "                lang_list = list(reference.keys())\n",
    "                for t in range(len(lang_list)):\n",
    "                    if (reference[lang_list[t]] != '<') or (reference[lang_list[t]] != '>') :\n",
    "                        reference_type_warn = reference_type_warn + 1\n",
    "    if 'False' not in reference_type:\n",
    "        print('正常，reference数据类型正确')\n",
    "    else:\n",
    "        print('异常，reference数据类型可能存在错误')\n",
    "        print('【reference数据类型可能存在错误的数据量 / 存在reference的数据总量】  <==>  【',reference_type_warn,'/',len(have_reference),'】\\n')\n",
    "        for i in range(len(have_reference)):\n",
    "            if not isinstance(have_reference.iloc[i]['reference'],str):\n",
    "                print('出现问题的reference数据类型：',type(have_reference.iloc[i]['reference']))\n",
    "                print('url：',have_reference.iloc[i]['url'][0],'\\n')\n",
    "            else:\n",
    "                if (have_reference.iloc[i]['reference'][0][lang] != '<') or (have_reference.iloc[i]['reference'][-1][lang] != '>') :\n",
    "                    print('reference可能非Html String类型：')\n",
    "                    print('url：',have_reference.iloc[i]['url'][0],'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少字段reference，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 reference字段数据缺失**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'reference' in data.columns:\n",
    "    no_reference = data[data['reference'].isnull()]\n",
    "    if len(no_reference) == 0:\n",
    "        print('正常，未发现reference字段缺失情况')\n",
    "    else:\n",
    "        print('异常，可能存在reference缺失现象')\n",
    "        print('【reference数据类型可能缺失的数据量 / 数据总量】  <==>  【',len(no_reference),'/',len(data),'】')\n",
    "        print('请从以下随机抽样检查，查看是否存在抓取遗漏：\\n')\n",
    "        for i in range(len(no_reference)):\n",
    "            print('url：',no_reference.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少字段reference，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 检查citation字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 检查 citation字段数据格式（citation-List[MultiLangHtmlString]）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'citation' in data.columns:\n",
    "    have_citation = data[data['citation'].notnull()]\n",
    "    citation_type = []\n",
    "    citation_type_warn = 0\n",
    "\n",
    "    for i in range(len(have_citation)):\n",
    "        citation_type.append(str(isinstance(have_citation.iloc[i]['citation'],list)))\n",
    "        if not isinstance(have_citation.iloc[i]['citation'],list):\n",
    "            citation_type_warn = citation_type_warn + 1\n",
    "        else:\n",
    "            paper_citation = have_citation.iloc[i]['citation']\n",
    "            for n in range(len(paper_citation)):\n",
    "                citation = paper_citation[n]\n",
    "                lang_list = list(citation.keys())\n",
    "                for t in range(len(lang_list)):\n",
    "                    if (citation[lang_list[t]] != '<') or (citation[lang_list[t]] != '>') :\n",
    "                        citation_type_warn = citation_type_warn + 1\n",
    "    if 'False' not in citation_type:\n",
    "        print('正常，citation数据类型正确')\n",
    "    else:\n",
    "        print('异常，citation数据类型可能存在错误')\n",
    "        print('【citation数据类型可能存在错误的数据量 / 存在citation的数据总量】  <==>  【',citation_type_warn,'/',len(have_citation),'】\\n')\n",
    "        for i in range(len(have_citation)):\n",
    "            if not isinstance(have_citation.iloc[i]['citation'],str):\n",
    "                print('出现问题的citation数据类型：',type(have_citation.iloc[i]['citation']))\n",
    "                print('url：',have_citation.iloc[i]['url'][0],'\\n')\n",
    "            else:\n",
    "                if (have_citation.iloc[i]['citation'][0][lang] != '<') or (have_citation.iloc[i]['citation'][-1][lang] != '>') :\n",
    "                    print('citation可能非Html String类型：')\n",
    "                    print('url：',have_citation.iloc[i]['url'][0],'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少字段citation，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 citation字段数据缺失**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'citation' in data.columns:\n",
    "    no_citation = data[data['citation'].isnull()]\n",
    "    if len(no_citation) == 0:\n",
    "        print('正常，未发现citation字段缺失情况')\n",
    "    else:\n",
    "        print('异常，可能存在citation缺失现象')\n",
    "        print('【citation数据类型可能缺失的数据量 / 数据总量】  <==>  【',len(no_citation),'/',len(data),'】')\n",
    "        print('请从以下随机抽样检查，查看是否存在抓取遗漏：\\n')\n",
    "        for i in range(len(no_citation)):\n",
    "            print('url：',no_citation.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少字段citation，请详细检查数据源')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============\n",
    "# 五. src、sid、venue、ts字段检查\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 检查src字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 src字段数据类型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'src' in data.columns:\n",
    "    have_src = data[data['src'].notnull()]\n",
    "    src_type = []\n",
    "    for i in range(len(have_src)):\n",
    "        src_type.append(str(isinstance(have_src.iloc[i]['src'],str)))\n",
    "    if 'False' not in src_type:\n",
    "        print('正常，src数据类型正确')\n",
    "    else:\n",
    "        print('异常，src数据类型可能存在错误\\n')\n",
    "        for i in range(len(have_src)):\n",
    "            src = have_src.iloc[i]['src']\n",
    "            if not isinstance(src,str):\n",
    "                print('src的数据类型为：',type(src))\n",
    "                print('url：',have_src.iloc[i]['url'][0])\n",
    "else:\n",
    "    print('异常，可能缺少必填字段src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 src字段数据问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'src' in data.columns:\n",
    "    have_src = data[data['src'].notnull()]\n",
    "    src = have_src.iloc[0]['src']\n",
    "    print('请详细检查，src字段应为 数据源名称')\n",
    "    print('src：',src)\n",
    "else:\n",
    "    print('异常，可能缺少必填字段src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 检查sid字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 sid字段数据重复**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidlist = []\n",
    "for sid in data['sid']:\n",
    "    sidlist.append(sid)\n",
    "\n",
    "sid_list = list(set(sidlist))\n",
    "\n",
    "if len(sid_list) == len(sidlist):\n",
    "    print('正常，未发现重复数据！')\n",
    "else:\n",
    "    print('异常，可能存在重复数据')\n",
    "    print('【重复数据量 / 数据总量】  <==>  【',len(sidlist)-len(sid_list),'/',len(data),'】\\n')\n",
    "\n",
    "    #展现重复元素和重复次数\n",
    "    repeation_tag = dict(Counter(sidlist))\n",
    "    for key,value in repeation_tag.items():\n",
    "        if value>1:\n",
    "            print('sid：',key,'\\t出现次数：',value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 检查venue字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 venue字段数据类型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'venue' in data.columns:\n",
    "    have_venue = data[data['venue'].notnull()]\n",
    "    venue_type = []\n",
    "    venue_type.append(str(isinstance(have_venue.iloc[0]['venue'],dict)))\n",
    "    venue_type.append(str(isinstance(have_venue.iloc[0]['venue']['name'],dict)))\n",
    "    venue_type.append(str(isinstance(have_venue.iloc[0]['venue']['type'],int)))\n",
    "    venue_type.append(str(isinstance(have_venue.iloc[0]['venue']['sid'],str)))\n",
    "    if 'False' not in venue_type:\n",
    "        print('正常，venue数据类型正确')\n",
    "    else:\n",
    "        print('异常，venue数据类型可能存在错误\\n')\n",
    "        venue = have_venue.iloc[0]['venue']\n",
    "        venue_name = have_venue.iloc[0]['venue']['name']\n",
    "        venue_type = have_venue.iloc[0]['venue']['type']\n",
    "        venue_sid = have_venue.iloc[0]['venue']['sid']\n",
    "        if (not isinstance(venue,dict)):\n",
    "            print('venue的数据类型应为：dict')\n",
    "            print('venue的数据类型为：',type(venue))\n",
    "        if (not isinstance(venue_name,dict)):\n",
    "            print('venue_name的数据类型应为：dict')\n",
    "            print('venue_name的数据类型为：',type(venue_name),'\\n')\n",
    "        if (not isinstance(venue_type,int)):\n",
    "            print('venue_type的数据类型应为：Int')\n",
    "            print('venue_type的数据类型为：',type(venue_type),'\\n')\n",
    "        if (not isinstance(venue_sid,str)):\n",
    "            print('venue_sid的数据类型应为：String')\n",
    "            print('venue_sid的数据类型为：',type(venue_sid),'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少必填字段venue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 检查 venue字段数据重复**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_name = []\n",
    "venue_type = []\n",
    "venue_sid = []\n",
    "for each in data['venue']:\n",
    "    venue_name.append(each['name'])\n",
    "    venue_type.append(each['type'])\n",
    "    venue_sid.append(each['sid'])\n",
    "\n",
    "#列表推导法\n",
    "name_list = []\n",
    "for one in venue_name:\n",
    "    if one not in name_list:\n",
    "        print(one)\n",
    "        name_list.append(one)\n",
    "if len(name_list) == 1:\n",
    "    print('正常，未发现venue_name字段重复')\n",
    "else:\n",
    "    print('venue中的name不止一个，请重新检查：',name_list)\n",
    "if len(set(venue_type)) == 1:\n",
    "    print('正常，未发现venue_type字段重复')\n",
    "else:\n",
    "    print('venue中的type不止一个，请重新检查：',set(venue_type))\n",
    "if len(set(venue_sid)) == 1:\n",
    "    print('正常，未发现venue_sid字段重复')\n",
    "else:\n",
    "    print('venue中的sid不止一个，请重新检查：',set(venue_sid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 检查 venue字段数据问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'venue' in data.columns:\n",
    "    have_venue = data[data['venue'].notnull()]\n",
    "    venue = have_venue.iloc[0]['venue']\n",
    "    venue_name = have_venue.iloc[0]['venue']['name']\n",
    "    venue_type = have_venue.iloc[0]['venue']['type']\n",
    "    venue_sid = have_venue.iloc[0]['venue']['sid']\n",
    "    print('请详细检查，以下venue字段是否符合规定\\n')\n",
    "    print('venue_name应为：论文中的期刊会议书籍名称')\n",
    "    print('venue_name为：',venue_name,'\\n')\n",
    "    print('venue_type应为：在venue表中定义的类别')\n",
    "    print('venue_type为：',venue_type,'\\n')\n",
    "    print('venue_sid应为：在数据源中的Source id')\n",
    "    print('venue_sid为：',venue_sid,'\\n')\n",
    "else:\n",
    "    print('异常，可能缺少必填字段venue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 检查ts字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 检查 ts字段数据类型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ts' in data.columns:\n",
    "    if '$date' in data.iloc[0]['ts'] :\n",
    "        ts = data.iloc[0]['ts']['$date']\n",
    "        if 'T' in ts:\n",
    "            ts = ts.split('.')[0].replace('T',' ')\n",
    "            try:\n",
    "                time.strptime(ts,\"%Y-%m-%d %H:%M:%S\")\n",
    "                tag = 0\n",
    "            except:\n",
    "                tag = 1\n",
    "        else:\n",
    "            tag = 1\n",
    "        if tag == 0:\n",
    "            print('正常，字段ts的数据格式可能正确')\n",
    "        else:\n",
    "            print('异常，字段ts的数据格式可能出现问题')\n",
    "        print(data.iloc[0]['ts']['$date'])\n",
    "    else:\n",
    "        print('异常，字段ts的数据格式可能出现问题')\n",
    "else:\n",
    "    print('异常，可能缺少必填字段ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
